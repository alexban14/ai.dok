name: ai-dok
services:
  client:
    build:
      context: ./client
      dockerfile: Dockerfile
    restart: unless-stopped
    env_file:
      - ./client/.env
    ports:
      - "9762:5173"
    depends_on:
      - llm_interaction_service
      - vector_db
    volumes:
      - ./client:/app
      - /app/node_modules
    networks:
      - ai_dok_network

  llm_interaction_service:
    hostname: llm_interaction_service
    build:
      context: ./llm_interaction_service
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - "9322:8000"
    volumes:
      - "./llm_interaction_service/app:/app/app"
      - llm_interaction_data:/home/app/.paddleocr
      - bm25_indexes:/app/bm25_indexes
    env_file:
      - ./llm_interaction_service/.env
    # Resource limits to prevent OOM killer
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    # Shared memory for PyTorch/transformers
    shm_size: '2gb'
    networks:
      - ai_dok_network

  vector_db:
    image: chromadb/chroma:latest
    ports:
      - "9422:8000"
    volumes:
      - vector_data:/data
    networks:
      - ai_dok_network

volumes:
  llm_interaction_data:
  vector_data:
  bm25_indexes:

networks:
  ai_dok_network:
    driver: bridge